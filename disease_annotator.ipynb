{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM40cPU7RZgHq15RqV/AvrQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8c203029bee348f086e928a55bba29b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c43b75959153407394b478f25a354b04",
              "IPY_MODEL_aaeda453480f4654b18bc2d984fb61dd",
              "IPY_MODEL_3a263d1a1b2048c3a5ae238d1cdaec4f"
            ],
            "layout": "IPY_MODEL_055c2c505c7d4b6d9b31931096e82810"
          }
        },
        "c43b75959153407394b478f25a354b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_370318697c05436398a89fd6bb66da39",
            "placeholder": "​",
            "style": "IPY_MODEL_8c1dd3f9e9ef48ebad1f1f2425d9ee9a",
            "value": "Downloading: 100%"
          }
        },
        "aaeda453480f4654b18bc2d984fb61dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f7ca4180cc64ef9b9cb161efe6be930",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1289df5da5646d59ec260ce45d3627e",
            "value": 213450
          }
        },
        "3a263d1a1b2048c3a5ae238d1cdaec4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1546986856474514b747ec8e6b54be40",
            "placeholder": "​",
            "style": "IPY_MODEL_4bf8b628ac7547b0b42054636b773358",
            "value": " 208k/208k [00:00&lt;00:00, 297kB/s]"
          }
        },
        "055c2c505c7d4b6d9b31931096e82810": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "370318697c05436398a89fd6bb66da39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c1dd3f9e9ef48ebad1f1f2425d9ee9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f7ca4180cc64ef9b9cb161efe6be930": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1289df5da5646d59ec260ce45d3627e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1546986856474514b747ec8e6b54be40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bf8b628ac7547b0b42054636b773358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d224dde43d541e1ac70c7cd32d909d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fda83a395ed4a3fa5afd4042a87af8e",
              "IPY_MODEL_60ac488406fd42b2b944ef4a185445da",
              "IPY_MODEL_3c015c6100d6423eae42dd62e65ce333"
            ],
            "layout": "IPY_MODEL_c74769cd7c494a36950c25086e6fc28e"
          }
        },
        "3fda83a395ed4a3fa5afd4042a87af8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2865959c27d4743907864b22acae366",
            "placeholder": "​",
            "style": "IPY_MODEL_e476689e24574191805d0557c16866b9",
            "value": "Downloading: 100%"
          }
        },
        "60ac488406fd42b2b944ef4a185445da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0ed8e5c14004397b6554bdedd261fa8",
            "max": 1110,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab2a9efa177d4629b9b18ec156eebc01",
            "value": 1110
          }
        },
        "3c015c6100d6423eae42dd62e65ce333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_830646e8e565487f9d0453750caf2eab",
            "placeholder": "​",
            "style": "IPY_MODEL_79e311af6c194f0fb55a1701292bc6c1",
            "value": " 1.08k/1.08k [00:00&lt;00:00, 9.44kB/s]"
          }
        },
        "c74769cd7c494a36950c25086e6fc28e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2865959c27d4743907864b22acae366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e476689e24574191805d0557c16866b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0ed8e5c14004397b6554bdedd261fa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab2a9efa177d4629b9b18ec156eebc01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "830646e8e565487f9d0453750caf2eab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79e311af6c194f0fb55a1701292bc6c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82ebe56a966141e68093320d988c4ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e65b58703c6f4235a29a8d17b5df2323",
              "IPY_MODEL_ccd273d636ed4ca084ef3cc0b79da3ac",
              "IPY_MODEL_73a339ce9f514aa690368052718339bf"
            ],
            "layout": "IPY_MODEL_8c5955ffc85e4cb7a30ff1d2fae7ed57"
          }
        },
        "e65b58703c6f4235a29a8d17b5df2323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c341f0677ca41738e12851d15b69f44",
            "placeholder": "​",
            "style": "IPY_MODEL_b7d494e9aba1417c91cbaf7bd27e0a0f",
            "value": "Downloading: 100%"
          }
        },
        "ccd273d636ed4ca084ef3cc0b79da3ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc7f7ecda40f4baaa838cfdc3d3d10d5",
            "max": 435783451,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e84098c9d290481e99671bc0e4e2561f",
            "value": 435783451
          }
        },
        "73a339ce9f514aa690368052718339bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c9dd833d83f488180963953eac30f6d",
            "placeholder": "​",
            "style": "IPY_MODEL_7500199f77cd46b4abe6dd06f56e3609",
            "value": " 416M/416M [00:22&lt;00:00, 24.9MB/s]"
          }
        },
        "8c5955ffc85e4cb7a30ff1d2fae7ed57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c341f0677ca41738e12851d15b69f44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7d494e9aba1417c91cbaf7bd27e0a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc7f7ecda40f4baaa838cfdc3d3d10d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e84098c9d290481e99671bc0e4e2561f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c9dd833d83f488180963953eac30f6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7500199f77cd46b4abe6dd06f56e3609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40eb263bc20d40e9a142cdecd5c05360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7d90a8c8a5846bfa29a5e1bd71d0154",
              "IPY_MODEL_545c3581135c4b64bc1971e8f1db4bb8",
              "IPY_MODEL_a8b8f52e86754bcebcf6f0a57a8be279"
            ],
            "layout": "IPY_MODEL_b0966d09aa924854b3983250e7680003"
          }
        },
        "c7d90a8c8a5846bfa29a5e1bd71d0154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0e88b19ee78418888e053670b2bd9a2",
            "placeholder": "​",
            "style": "IPY_MODEL_22899254c8ba4ac8b657a2f2afbf8a71",
            "value": "Downloading: 100%"
          }
        },
        "545c3581135c4b64bc1971e8f1db4bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee783cb5e7ac4c0d99d38555fe8a6d19",
            "max": 313,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4192bc915e0e434e904b7e17685800fb",
            "value": 313
          }
        },
        "a8b8f52e86754bcebcf6f0a57a8be279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_745ce6f32e6e40a093f6049064a919a1",
            "placeholder": "​",
            "style": "IPY_MODEL_c1022334bb9f4c4183ad0e2a059ef65b",
            "value": " 313/313 [00:00&lt;00:00, 2.30kB/s]"
          }
        },
        "b0966d09aa924854b3983250e7680003": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0e88b19ee78418888e053670b2bd9a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22899254c8ba4ac8b657a2f2afbf8a71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee783cb5e7ac4c0d99d38555fe8a6d19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4192bc915e0e434e904b7e17685800fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "745ce6f32e6e40a093f6049064a919a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1022334bb9f4c4183ad0e2a059ef65b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f623d40aa83e4197900a0ae46c62543e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7554a3ad5e284f0ca6a40374dca1dc0d",
              "IPY_MODEL_5fba35b3327e4a32a9bca2a91fda0b3c",
              "IPY_MODEL_071dc1f383bd4e46b2d762682d77aa5c"
            ],
            "layout": "IPY_MODEL_218cfc0b9d1341ddb7adadad3769c3b1"
          }
        },
        "7554a3ad5e284f0ca6a40374dca1dc0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a2986ff629e44529c219f74bfc3692f",
            "placeholder": "​",
            "style": "IPY_MODEL_30a35b8dbdb44a81bd002e99d6fcb658",
            "value": "Downloading: 100%"
          }
        },
        "5fba35b3327e4a32a9bca2a91fda0b3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3924565793704a5091d0c729acef6da8",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11cff03a77a24c3cb6a7d24e0a4789f8",
            "value": 213450
          }
        },
        "071dc1f383bd4e46b2d762682d77aa5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a6924d6388141cf9f5e76e21fea1a35",
            "placeholder": "​",
            "style": "IPY_MODEL_7002c9ccf8024cab98b6364bcde73b46",
            "value": " 208k/208k [00:00&lt;00:00, 528kB/s]"
          }
        },
        "218cfc0b9d1341ddb7adadad3769c3b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a2986ff629e44529c219f74bfc3692f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30a35b8dbdb44a81bd002e99d6fcb658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3924565793704a5091d0c729acef6da8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11cff03a77a24c3cb6a7d24e0a4789f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a6924d6388141cf9f5e76e21fea1a35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7002c9ccf8024cab98b6364bcde73b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe289f09ea1946ba8e5290ce679b70bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3c2fe052b12481fae56a5888cc9fbc3",
              "IPY_MODEL_be2cf9fedac84b748a40b17ca91cb285",
              "IPY_MODEL_37a45dfef49e4894a856191d2c268ad1"
            ],
            "layout": "IPY_MODEL_ed54ef39f7124924af2f893e374fac6d"
          }
        },
        "e3c2fe052b12481fae56a5888cc9fbc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85e1f2c5044440e49bc05f126debd0ae",
            "placeholder": "​",
            "style": "IPY_MODEL_4a4847d14eeb4003ae1d2ded4bbe248a",
            "value": "Downloading: 100%"
          }
        },
        "be2cf9fedac84b748a40b17ca91cb285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03f315ed6b4d4fb5bebe088602218299",
            "max": 435780550,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7408f2a8fff48dba28b195c879502ea",
            "value": 435780550
          }
        },
        "37a45dfef49e4894a856191d2c268ad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3e1d46ff2a442009ef240097ecd6a00",
            "placeholder": "​",
            "style": "IPY_MODEL_b9c2757672ef4a8484df9aa15fe7fb95",
            "value": " 416M/416M [00:22&lt;00:00, 17.8MB/s]"
          }
        },
        "ed54ef39f7124924af2f893e374fac6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85e1f2c5044440e49bc05f126debd0ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a4847d14eeb4003ae1d2ded4bbe248a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03f315ed6b4d4fb5bebe088602218299": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7408f2a8fff48dba28b195c879502ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3e1d46ff2a442009ef240097ecd6a00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9c2757672ef4a8484df9aa15fe7fb95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/balbatra/disease-annotator/blob/main/disease_annotator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjHD9pLHuZUf"
      },
      "source": [
        "# Make use of GPU\n",
        "\n",
        "Since we are going to train a large neural network it's best to use a GPU, otherwise training will take a very long time. Google Colab offers free GPUs. These GPUs can be selected by going to Runtime -> Change runtime type -> Hardware accelerator and choosing GPU\n",
        "\n",
        "In order to tell pyTorch to use the GPU, we need to specify the GPU as a device. This device is going to be used Later to process the data in the training loop\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gncsuKDYtoOs",
        "outputId": "c6819321-e45e-4743-b8f6-d3f928d28400"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('%d GPU(s) are available. The type of the GPU(s) is: %s'% (torch.cuda.device_count(), torch.cuda.get_device_name(0)))\n",
        "\n",
        "else:\n",
        "    print('No GPU is available, using CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU is available, using CPU instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVLm-xnzVkDY"
      },
      "source": [
        "# Reading NCBI and BC5CDR Data\n",
        "\n",
        "We want to fine tune biobert by using ncbi and BC5CDR data. The data is a single tsv file. The tsv file includes tab separated values.\n",
        "\n",
        "Each line of the tsv file includes a single word and the tag of this word or entity. The tsv file has no sentence ids but sentences are splitted by new lines.\n",
        "The tag follows a special format used widely in NER literature called the IOB format (Inside, Outside, Beginning Format). This format gives us a way to not only tag entities, but to indicate which words are part of the same entity:\n",
        "\n",
        "\n",
        "*   B: this tag means the word is either a single-word entity name, or else the first word in a multi-word entity name.\n",
        "*   I: this tag means the word is part of a multi-word entity, but is not the first word in the full entity name.\n",
        "*   O: this tag means the word is not part of an entity.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjSEQHJwaW8Y"
      },
      "source": [
        "We first mount the google drive where the data is located"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm5Yh1RafzXs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6db068d-2f53-4623-e6bb-ec4eaed329c6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld0IMIGrxi6q"
      },
      "source": [
        "Install Pandas to be able to prepare ncbi and BC5CDR data for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZJMJpOTxjMe",
        "outputId": "e42c5535-77ab-4f79-ef12-20c4509dc023"
      },
      "source": [
        "!pip install pandas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4l_paNDxre8"
      },
      "source": [
        "This method transforms the AZDC data to two arrays. The first array sentences_AZDC is an array of arrays. the sub arrays are the sentences. The second array labels_AZDC is also an array of arrays. The sub arrays are the labels of the sentences in sentences_AZDC. Eech sentence in sentences_AZDC has a corresponding array in labels_AZDC including its labels. The file /content/drive/MyDrive/MedBrain/diseases.tsv can be transformed using this procedure. Also unique_labels_AZDC which is an array including all unique lables usually O, B, I is created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Npg1tv69ALIo"
      },
      "source": [
        "import re\n",
        "\n",
        "sentences_AZDC = []\n",
        "labels_AZDC = []\n",
        "unique_labels_AZDC = set()\n",
        "\n",
        "\n",
        "def transform_AZDC (data):\n",
        "  sentence = data.iloc[0]['Sentence']\n",
        "  old_start_point = None\n",
        "  old_end_point = None\n",
        "  final_sentence = []\n",
        "  final_sentence_labels = []\n",
        "  for index, row in data.iterrows():\n",
        "    start_point = int(row['Start Point']-1)\n",
        "    end_point = int(row['End Point'])\n",
        "    if(old_end_point is None or start_point > old_end_point):\n",
        "      if(old_end_point is None):\n",
        "        if(start_point!=0):\n",
        "          text = sentence[0:start_point]\n",
        "          text = re.sub('([^a-zA-Z0-9\\s])', r' \\1 ', text)\n",
        "          text = re.sub('\\s+', r' ', text)\n",
        "          text = re.split(r\"\\s\",text)\n",
        "          text = list(filter(None, text))\n",
        "          text_labels = ['O']*len(text)\n",
        "          final_sentence.extend(text)\n",
        "          final_sentence_labels.extend(text_labels)\n",
        "      else:\n",
        "        text = sentence[old_end_point:start_point]\n",
        "        text = re.sub('([^a-zA-Z0-9\\s])', r' \\1 ', text)\n",
        "        text = re.sub('\\s+', r' ', text)\n",
        "        text = re.split(r\"\\s\",text)\n",
        "        text = list(filter(None, text))\n",
        "        text_labels = ['O']*(len(text))\n",
        "        final_sentence.extend(text)\n",
        "        final_sentence_labels.extend(text_labels)\n",
        "      text2 = sentence[start_point:end_point]\n",
        "      text2 = re.sub('([^a-zA-Z0-9\\s])', r' \\1 ', text2)\n",
        "      text2 = re.sub('\\s+', r' ', text2)\n",
        "      text2 = re.split(r\"\\s\",text2)\n",
        "      text2 = list(filter(None, text2))\n",
        "      text_labels2 = ['I']*(len(text2)-1)\n",
        "      text_labels2.insert(0, 'B')\n",
        "      final_sentence.extend(text2)\n",
        "      final_sentence_labels.extend(text_labels2)\n",
        "      old_start_point = start_point\n",
        "      old_end_point = end_point\n",
        "  text3 = sentence[end_point::]\n",
        "  text3 = re.sub('([^a-zA-Z0-9\\s])', r' \\1 ', text3)\n",
        "  text3 = re.sub('\\s+', r' ', text3)\n",
        "  text3 = re.split(r\"\\s\",text3)\n",
        "  text3 = list(filter(None, text3))\n",
        "  text_labels3 = ['O']*len(text3)\n",
        "  final_sentence.extend(text3)\n",
        "  final_sentence_labels.extend(text_labels3)\n",
        "  sentences_AZDC.append(final_sentence)\n",
        "  labels_AZDC.append(final_sentence_labels)\n",
        "  unique_labels_AZDC.update(final_sentence_labels)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The excution of the transform_AZDC is done in this snippet. First the data is cleaned by removing rows including null values. Then the rows are sorted by start Point which is the starting index of a disease name in a document and at the end grouped by the Doc Id. The result is rows of a specific doc id are grouped togather and sorted by start point."
      ],
      "metadata": {
        "id": "2OmnF-lZo9_U"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "7FvSkmxnxrrJ",
        "outputId": "0f8b0aed-a1cc-44e3-c803-39fc08d2690a"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/MedBrain/diseases.tsv', sep='\\t')\n",
        "df = df[df['Start Point'].notna()]\n",
        "df = df[df['End Point'].notna()]\n",
        "df.sort_values(by=['Start Point'], inplace=True)\n",
        "df.groupby(\"Doc Id\").apply(transform_AZDC)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46124aee-e3ac-4a56-ae17-9c37ff3d8ba8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46124aee-e3ac-4a56-ae17-9c37ff3d8ba8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46124aee-e3ac-4a56-ae17-9c37ff3d8ba8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46124aee-e3ac-4a56-ae17-9c37ff3d8ba8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZgWlvoYajw5"
      },
      "source": [
        "We need a method which reads a tsv file and returns tuples of sentences and labels. Each tuple includes a sentence and labels of words included in the sentence. The tsv file of each dataset is stored on the my drive under /content/drive/MyDrive/MedBrain/**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hrrXeAaVkVz"
      },
      "source": [
        "import re\n",
        "\n",
        "def read_data(input_file):\n",
        "  # List of all sentences in the dataset.\n",
        "  sentences = []\n",
        "  labels = []\n",
        "\n",
        "  # Lists to store the current sentence.\n",
        "  tokens = []\n",
        "  token_labels = []\n",
        "\n",
        "  # Gather the set of unique labels.\n",
        "  unique_labels = set()\n",
        "\n",
        "  # Read the dataset line by line. Each line of the file\n",
        "  # is either empty or has two tokens, separated by a tab.\n",
        "  with open(input_file, newline = '') as lines:\n",
        "\n",
        "\n",
        "    for line in lines:\n",
        "\n",
        "        # If we encounter a blank line, it means we've completed the previous\n",
        "        # sentence.\n",
        "        word_and_label = re.split(r'\\t+', line.rstrip(\"\\n\").strip())\n",
        "\n",
        "        if word_and_label == ['']:\n",
        "\n",
        "            # Add the completed sentence.\n",
        "            sentences.append(tokens)\n",
        "            labels.append(token_labels)\n",
        "\n",
        "            # Start a new sentence.\n",
        "            tokens = []\n",
        "            token_labels = []\n",
        "\n",
        "        else:\n",
        "            # Add the token and its label to the current sentence.\n",
        "            tokens.append(word_and_label[0])\n",
        "            token_labels.append(word_and_label[1])\n",
        "\n",
        "            # Add the label to the set (no effect if it already exists).\n",
        "            unique_labels.add(word_and_label[1])\n",
        "  return sentences, labels , unique_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbCQ_3wE0sOL"
      },
      "source": [
        "let us inspect the data a little bit by printing out the number of sentences, an example sentence and the corresponding tags of each dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHzU_iGpCiql",
        "outputId": "6b6b1145-988c-41f9-c2c6-f2c3678b8862"
      },
      "source": [
        "sentences_ncbi, labels_ncbi, unique_labels_ncbi = read_data('/content/drive/MyDrive/MedBrain/NCBI/train.tsv')\n",
        "print(\"We have {} sentences in the ncbi train set\".format(len(sentences_ncbi)))\n",
        "sentences_ncbi_devel, labels_ncbi_devel, unique_labels_ncbi_devel = read_data('/content/drive/MyDrive/MedBrain/NCBI/devel.tsv')\n",
        "print(\"We have {} sentences in the ncbi devel set\".format(len(sentences_ncbi_devel)))\n",
        "sentences_bc5cdr, labels_bc5cdr, unique_labels_bc5cdr = read_data('/content/drive/MyDrive/MedBrain/BC5CDR/train.tsv')\n",
        "print(\"We have {} sentences in the bc5cdr train set\".format(len(sentences_bc5cdr)))\n",
        "sentences_bc5cdr_devel, labels_bc5cdr_devel, unique_labels_bc5cdr_devel = read_data('/content/drive/MyDrive/MedBrain/BC5CDR/devel.tsv')\n",
        "print(\"We have {} sentences in the bc5cdr devel set\".format(len(sentences_bc5cdr_devel)))\n",
        "print(\"We have {} sentences in the AZDC train set\".format(len(sentences_AZDC)))\n",
        "sentences = []\n",
        "sentences.extend(sentences_ncbi)\n",
        "sentences.extend(sentences_bc5cdr)\n",
        "sentences.extend(sentences_ncbi_devel)\n",
        "sentences.extend(sentences_bc5cdr_devel)\n",
        "sentences.extend(sentences_AZDC)\n",
        "\n",
        "labels = []\n",
        "labels.extend(labels_ncbi)\n",
        "labels.extend(labels_bc5cdr)\n",
        "labels.extend(labels_ncbi_devel)\n",
        "labels.extend(labels_bc5cdr_devel)\n",
        "labels.extend(labels_AZDC)\n",
        "\n",
        "unique_labels = unique_labels_AZDC.union(unique_labels_ncbi.union(unique_labels_bc5cdr))\n",
        "print(\"Number of training sentences: {:,}\".format(len(sentences)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 5423 sentences in the ncbi train set\n",
            "We have 923 sentences in the ncbi devel set\n",
            "We have 4559 sentences in the bc5cdr train set\n",
            "We have 4581 sentences in the bc5cdr devel set\n",
            "We have 1734 sentences in the AZDC train set\n",
            "Number of training sentences: 17,220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd_OVkK5tzRK"
      },
      "source": [
        "# Installing The dependencies and implementing helper methods\n",
        "We are going to install the huggingface library, which provides State-of-the-art Natural Language Processing for Pytorch and TensorFlow 2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKr-vNCVZslq",
        "outputId": "2e0938c3-e3ab-4c97-bb0a-4f14795c68b8"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 53.4 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 30.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpXb_E2BK_6g"
      },
      "source": [
        "We'll use the wget package to download the pretrained biobert model and tokinzer to google driver file system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7O7DjklsK_Ac",
        "outputId": "a08cbd96-2c3c-4bb7-94b3-9a93ac77443d"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=fe6c1f1c7e5283f555003716921561b5229cff70f6e2f621add7845429d5bd10\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj6h8KOV_juc"
      },
      "source": [
        "To feed BERT with sentences. We first map a sentence to tokens. Each word of a sentence can be mapped to one or more tokens. This means that a token is a whole word or a subword of a word. therefore a word can either be represented by only one token or by several tokens. Using this mechanism a tokenizer can almost always map words to tokens, also unseen words. Tokens are then mapped to their index in the tokenizer vocabulary. At the end the tokens are mapped to embeddings. Theses embeddings are the input of the first layer of the 12 Transformer layers of BERT. Each transformer takes in a list of token embeddings, and produces the same number of embeddings on the output but with the values changed, of course. In the following I use code from biobert-pytorch to download and convert the biobert model to a pytorch model and also to get the tokenizer. I copied the source since I upgrades the libraries used in biobert-pytorch (Old Code)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjNrU7ou_kX1"
      },
      "source": [
        "from docopt import docopt\n",
        "import wget\n",
        "import shutil\n",
        "import os\n",
        "from os import path\n",
        "\n",
        "from transformers import BertTokenizer, BertForTokenClassification\n",
        "\n",
        "\n",
        "def get_default_biobert_path():\n",
        "    \"\"\"\n",
        "    :return: path \"/content/drive/MyDrive/MedBrain/biobert\n",
        "    \"\"\"\n",
        "    return '/content/drive/MyDrive/MedBrain/biobert'\n",
        "\n",
        "\n",
        "def download_and_extract(target_directory):\n",
        "    \"\"\"\n",
        "    Downloads and extracts biobert weights\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if(path.exists('/content/drive/MyDrive/MedBrain/biobert')):\n",
        "      return\n",
        "    force_download_and_extract(target_directory)\n",
        "\n",
        "def force_download_and_extract(target_directory):\n",
        "    \"\"\"\n",
        "    Downloads and extracts biobert weights\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # Make sure that directory for pannuke exists\n",
        "    os.makedirs(target_directory, exist_ok=True)\n",
        "    wget.download(LINK, out=target_directory)\n",
        "    downloaded_file_path = os.path.join(target_directory, \"biobert_weights.zip\")\n",
        "    shutil.unpack_archive(downloaded_file_path, target_directory)\n",
        "    os.remove(downloaded_file_path)\n",
        "\n",
        "\n",
        "def parse_arguments(arguments):\n",
        "    user_directory = arguments[\"--dir\"]\n",
        "    target_directory = user_directory if user_directory else get_default_biobert_path()\n",
        "    return target_directory\n",
        "\n",
        "\n",
        "def _load_model(model_dir):\n",
        "    assert os.path.exists(model_dir)\n",
        "    model = BertForTokenClassification.from_pretrained(\n",
        "    model_dir,\n",
        "    # we have 4 labels B, I, O and [PAD]\n",
        "    num_labels=4,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False\n",
        "    )\n",
        "    # model = BertModel.from_pretrained(model_dir)\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_biobert(download=False):\n",
        "    \"\"\"\n",
        "    Loads biobert model, if weights are not available it will download it\n",
        "    :param model_dir: Location where model weights are stored or should be downloaded to\n",
        "    :param download: If model weights should be downloaded\n",
        "    :return: HuggingFace BertModel\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    if (download == True):\n",
        "        download_and_extract(get_default_biobert_path())\n",
        "\n",
        "    return _load_model(MODEL_DIR)\n",
        "\n",
        "MODEL_DIR = os.path.join(get_default_biobert_path(), \"biobert_v1.1_pubmed\")\n",
        "LINK = \"https://www.dropbox.com/s/dc2ki2d4jv8isrb/biobert_weights.zip?dl=1\"\n",
        "VOCAB_FILE = os.path.join(MODEL_DIR, \"vocab.txt\")\n",
        "\n",
        "def get_tokenizer(vocab_file=None):\n",
        "    vocab_file = VOCAB_FILE if vocab_file is None else vocab_file\n",
        "    os.path.isfile(vocab_file)\n",
        "    tokenizer = BertTokenizer(vocab_file=vocab_file, do_lower_case=False)\n",
        "    return tokenizer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9Br_RmxV8rn"
      },
      "source": [
        "In the folowing we create a BertForTokenClassification model from a BertForPreTraining model. This means all the model layers of the BertForTokenClassification which are not found in BertForPreTraining are going to be randomly initialzed. This means we need to train the model to get somthing usfull. We first download the tokenizer to create input tokens out of the sentences (old code)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fzhnf3RW5CQ3"
      },
      "source": [
        "download_and_extract(get_default_biobert_path())\n",
        "tokenizer = get_tokenizer()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a new model biobert base 1.2. I will download it instead of using the old model in the cell above. which is biobert 1.1. I initialize the model BertForTokenClassification which can be used to classify tokens and initialize the tokenizer. We have 4 labels and do not want to output the hidden states and output attensions also the tokenizer uses capital and small letters."
      ],
      "metadata": {
        "id": "3BZ9YlozxbBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForTokenClassification\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.2\", do_lower_case=False)\n",
        "\n",
        "\n",
        "model = BertForTokenClassification.from_pretrained(\n",
        "    \"dmis-lab/biobert-base-cased-v1.2\",\n",
        "    # we have 4 labels B, I, O and [PAD]\n",
        "    num_labels=4,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "8c203029bee348f086e928a55bba29b8",
            "c43b75959153407394b478f25a354b04",
            "aaeda453480f4654b18bc2d984fb61dd",
            "3a263d1a1b2048c3a5ae238d1cdaec4f",
            "055c2c505c7d4b6d9b31931096e82810",
            "370318697c05436398a89fd6bb66da39",
            "8c1dd3f9e9ef48ebad1f1f2425d9ee9a",
            "9f7ca4180cc64ef9b9cb161efe6be930",
            "c1289df5da5646d59ec260ce45d3627e",
            "1546986856474514b747ec8e6b54be40",
            "4bf8b628ac7547b0b42054636b773358",
            "5d224dde43d541e1ac70c7cd32d909d7",
            "3fda83a395ed4a3fa5afd4042a87af8e",
            "60ac488406fd42b2b944ef4a185445da",
            "3c015c6100d6423eae42dd62e65ce333",
            "c74769cd7c494a36950c25086e6fc28e",
            "f2865959c27d4743907864b22acae366",
            "e476689e24574191805d0557c16866b9",
            "a0ed8e5c14004397b6554bdedd261fa8",
            "ab2a9efa177d4629b9b18ec156eebc01",
            "830646e8e565487f9d0453750caf2eab",
            "79e311af6c194f0fb55a1701292bc6c1",
            "82ebe56a966141e68093320d988c4ef0",
            "e65b58703c6f4235a29a8d17b5df2323",
            "ccd273d636ed4ca084ef3cc0b79da3ac",
            "73a339ce9f514aa690368052718339bf",
            "8c5955ffc85e4cb7a30ff1d2fae7ed57",
            "8c341f0677ca41738e12851d15b69f44",
            "b7d494e9aba1417c91cbaf7bd27e0a0f",
            "fc7f7ecda40f4baaa838cfdc3d3d10d5",
            "e84098c9d290481e99671bc0e4e2561f",
            "2c9dd833d83f488180963953eac30f6d",
            "7500199f77cd46b4abe6dd06f56e3609"
          ]
        },
        "id": "g9H6FcR5TQDZ",
        "outputId": "16af9760-a4b7-4069-bf59-d3fcf4b9240e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c203029bee348f086e928a55bba29b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d224dde43d541e1ac70c7cd32d909d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82ebe56a966141e68093320d988c4ef0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.2 were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emaJYSxn5TgP"
      },
      "source": [
        "Let’s apply the tokenizer to one sentence just to see the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJLOeNaE5ZBt",
        "outputId": "25285faf-e9c4-43fc-e815-fafe594b139a"
      },
      "source": [
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "sentence = \" \".join(sentences[0])\n",
        "\n",
        "print('Tokenized: ', tokenizer.tokenize(sentence))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentence)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  ['Identification', 'of', 'APC2', ',', 'a', 'homologue', 'of', 'the', 'adenomatous', 'polyposis', 'coli', 'tumour', 'suppressor', '.']\n",
            "Tokenized:  ['I', '##dent', '##ification', 'of', 'AP', '##C', '##2', ',', 'a', 'ho', '##mo', '##logue', 'of', 'the', 'ad', '##eno', '##mat', '##ous', 'p', '##oly', '##po', '##sis', 'co', '##li', 't', '##umour', 'suppress', '##or', '.']\n",
            "Token IDs:  [146, 11951, 5783, 1104, 10997, 1658, 1477, 117, 170, 16358, 3702, 12733, 1104, 1103, 8050, 26601, 21943, 2285, 185, 23415, 5674, 4863, 1884, 2646, 189, 27226, 17203, 1766, 119]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN-QAa2t5fT6"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XjTMD4b5fmt",
        "outputId": "58a06144-77c2-4229-c433-238da19b53c6"
      },
      "source": [
        "# Map each unique label to an integer.\n",
        "unique_labels_sorted = list(unique_labels)\n",
        "unique_labels_sorted.sort()\n",
        "label_2_index_map = {label:index for index, label in enumerate(unique_labels_sorted)}\n",
        "label_2_index_map.update({'X':-100})\n",
        "index_2_label_map = {index:label for index, label in enumerate(unique_labels_sorted)}\n",
        "index_2_label_map.update({-100:'X'})\n",
        "\n",
        "print(label_2_index_map)\n",
        "print(index_2_label_map)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'B': 0, 'I': 1, 'O': 2, 'X': -100}\n",
            "{0: 'B', 1: 'I', 2: 'O', -100: 'X'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmToJHzQ8K9C"
      },
      "source": [
        "plot the distibution of sentence lengths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "L2rcIA7l8Qrb",
        "outputId": "0782516e-b614-4e58-efe5-f46ef6c44d8c"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Record the length of each sequence.\n",
        "lengths = []\n",
        "\n",
        "# For every sentence...\n",
        "for sen in sentences:\n",
        "\n",
        "    # Reconstruct the sentence to let BERT decide how to tokenize it.\n",
        "    sen = ' '.join(sen)\n",
        "\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sen,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "\n",
        "    # Record the length of the sentence after tokenization.\n",
        "    lengths.append(len(encoded_sent))\n",
        "print('   Min length: {:,} tokens'.format(min(lengths)))\n",
        "print('   Max length: {:,} tokens'.format(max(lengths)))\n",
        "print('Median length: {:,} tokens'.format(int(np.median(lengths))))\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
        "\n",
        "# Plot the distribution of comment lengths.\n",
        "sns.distplot(lengths, kde=False, rug=False)\n",
        "\n",
        "plt.title('Sentence Lengths')\n",
        "plt.xlabel('Sentence Length')\n",
        "plt.ylabel('# of Sentences')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Min length: 4 tokens\n",
            "   Max length: 300 tokens\n",
            "Median length: 35 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, '# of Sentences')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63AKzZcP-upE"
      },
      "source": [
        "tokenize the sentences where input_ids is an array of arrays each sub array include a tokenized sentence. attension_masks are to check which tokens are relevant."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhMiAJ9T-u7A",
        "outputId": "5787ce8a-e85e-4115-b428-eea1cf36ac28"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Reconstruct the sentence--otherwise `tokenizer` will interpret the list\n",
        "    # of string tokens as having already been tokenized by BERT.\n",
        "    sent_str = ' '.join(sent)\n",
        "\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent_str,                  # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        truncation = True,\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_dict['input_ids'][0])\n",
        "\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'][0])\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])\n",
        "print('Masks:', attention_masks[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  ['Identification', 'of', 'APC2', ',', 'a', 'homologue', 'of', 'the', 'adenomatous', 'polyposis', 'coli', 'tumour', 'suppressor', '.']\n",
            "Token IDs: tensor([  101,   146, 11951,  5783,  1104, 10997,  1658,  1477,   117,   170,\n",
            "        16358,  3702, 12733,  1104,  1103,  8050, 26601, 21943,  2285,   185,\n",
            "        23415,  5674,  4863,  1884,  2646,   189, 27226, 17203,  1766,   119,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n",
            "Masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smbeHNNTcwY-"
      },
      "source": [
        "This snippet is simple it is about labeling the tokens. After tokenization some words are tokenized to more thant one token. At the end the number of tokens in a sentence and the number of labels are going to be more than the number of words and original labels. The algorithm is going to assign all tokens of a specific word the same token as the original token of the word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDCfJPLjFn0r"
      },
      "source": [
        "# New labels for all of the input sentences.\n",
        "new_labels = []\n",
        "\n",
        "# The special label ID we'll give to \"extra\" tokens.\n",
        "null_label_id = -100\n",
        "\n",
        "# For each sentence...\n",
        "for (sen, orig_labels) in zip(input_ids, labels):\n",
        "\n",
        "    # Create a new list to hold the adjusted labels for this sentence.\n",
        "    padded_labels = []\n",
        "\n",
        "    # This will be our index into the original label list.\n",
        "    orig_labels_i = 0\n",
        "\n",
        "    # For each token in the padded sentence...\n",
        "    for token_id in sen:\n",
        "\n",
        "        # Pull the value out of the tensor.\n",
        "        token_id = token_id.numpy().item()\n",
        "\n",
        "        # If `[PAD]`, `[CLS]`, or `[SEP]`...\n",
        "        if (token_id == tokenizer.pad_token_id) or \\\n",
        "            (token_id == tokenizer.cls_token_id) or \\\n",
        "            (token_id == tokenizer.sep_token_id):\n",
        "\n",
        "            # Assign it the null label.\n",
        "            padded_labels.append(null_label_id)\n",
        "\n",
        "        # If the token string starts with \"##\"...\n",
        "        elif tokenizer.convert_ids_to_tokens(token_id)[0:2] == '##':\n",
        "\n",
        "            # It's a subword token, and not part of the original dataset, so\n",
        "            # assign it the null label.\n",
        "            padded_labels.append(label_2_index_map[orig_labels[orig_labels_i-1]])\n",
        "\n",
        "        # If it's not any of the above...\n",
        "        else:\n",
        "\n",
        "            # This token corresponds to one of the original ones, so assign it\n",
        "            # it's original label.\n",
        "\n",
        "            # Look up the label for this token.\n",
        "            label_str = orig_labels[orig_labels_i]\n",
        "\n",
        "            # Map the label to its ID, and assign it.\n",
        "            padded_labels.append(label_2_index_map[label_str])\n",
        "\n",
        "            # Increment our index into the original labels list.\n",
        "            orig_labels_i += 1\n",
        "\n",
        "    # If we did this right, then the new `padded_labels` list should match\n",
        "    # the length of the tokenized sentence.\n",
        "    assert(len(sen) == len(padded_labels))\n",
        "\n",
        "    # Store the updated labels list for this sentence.\n",
        "    new_labels.append(padded_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLwhDffxdYp3"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVWvfwARdY2k",
        "outputId": "6563f1de-9898-4965-87e4-fe328288b81e"
      },
      "source": [
        "print('\\nSentence:    ', sentences[100])\n",
        "print('\\nLabels:      ', labels[100])\n",
        "print('\\nBERT Tokens: ', tokenizer.tokenize(' '.join(sentences[100])))\n",
        "print('\\nToken IDs:   ', input_ids[100])\n",
        "print('\\nNew Labels:  ', list(map(lambda x: index_2_label_map[x],  new_labels[100])))\n",
        "print('\\nMask:        ', attention_masks[100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence:     ['The', 'positive', 'control', 'for', 'DMT1', 'up', '-', 'regulation', 'was', 'a', 'murine', 'model', 'of', 'dietary', 'iron', 'deficiency', 'that', 'demonstrated', 'greatly', 'increased', 'levels', 'of', 'duodenal', 'DMT1', '(', 'IRE', ')', 'mRNA', '.']\n",
            "\n",
            "Labels:       ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "BERT Tokens:  ['The', 'positive', 'control', 'for', 'D', '##MT', '##1', 'up', '-', 'regulation', 'was', 'a', 'm', '##uri', '##ne', 'model', 'of', 'diet', '##ary', 'iron', 'deficiency', 'that', 'demonstrated', 'greatly', 'increased', 'levels', 'of', 'duo', '##den', '##al', 'D', '##MT', '##1', '(', 'I', '##RE', ')', 'm', '##RNA', '.']\n",
            "\n",
            "Token IDs:    tensor([  101,  1109,  3112,  1654,  1111,   141, 13910,  1475,  1146,   118,\n",
            "         8585,  1108,   170,   182,  8212,  1673,  2235,  1104, 10211,  3113,\n",
            "         3926, 21344,  1115,  7160,  5958,  2569,  3001,  1104,  6862,  2883,\n",
            "         1348,   141, 13910,  1475,   113,   146, 16941,   114,   182, 15654,\n",
            "          119,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n",
            "\n",
            "New Labels:   ['X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X']\n",
            "\n",
            "Mask:         tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWz9gm73_euV"
      },
      "source": [
        "convert the data into pyThorch tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lnFfJE5_e53"
      },
      "source": [
        "# Convert the lists into PyTorch tensors.\n",
        "\n",
        "# `input_ids` is a list of tensor arrays--stack them into a matrix with size\n",
        "# [7,660  x  50].\n",
        "pt_input_ids = torch.stack(input_ids, dim=0)\n",
        "\n",
        "# `attention_masks` is a list of tensor arrays--stack them into a matrix with\n",
        "# size [7,660  x  50].\n",
        "pt_attention_masks = torch.stack(attention_masks, dim=0)\n",
        "\n",
        "# Labels is a list of lists. Convert it into a tensor matrix with size\n",
        "# [7,660  x  50].\n",
        "pt_labels = torch.tensor(new_labels, dtype=torch.long)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqhiU0zu_lhC"
      },
      "source": [
        "split train and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEzhvpDNCBKh",
        "outputId": "0ff76e1a-4b8a-40cf-ccf6-489adc05620a"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(pt_input_ids, pt_attention_masks, pt_labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13,776 training samples\n",
            "3,444 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOIqBmXTCfxt"
      },
      "source": [
        "configure dataloader with batchsize of 16 and a random sampler. for validation set not need for random sampler."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWL-EyArCgBE"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it\n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch\n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order.\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsJIzAsmCpDT"
      },
      "source": [
        "# This is the number of labels in our dataset, so we will be doing 4-way classification (all labels plus our padding label)\n",
        "\n",
        "B, I, O, X"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekvB92tdCpNa",
        "outputId": "7f0aa264-1368-4d03-d5a0-11f85894f902"
      },
      "source": [
        "# This is the number of labels in our dataset, so we will be doing 4-way classification (all labels plus our padding label)\n",
        "len(label_2_index_map)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVXPx_2IC16c"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the model to GPU"
      ],
      "metadata": {
        "id": "l7TlfSCT5p6I"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "v0BRjLlxC2D0",
        "outputId": "39310583-68d6-4996-aa11-273f150cfab8"
      },
      "source": [
        "#model = get_biobert()\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-d838bae36fd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#model = get_biobert()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmj0OXziII5e"
      },
      "source": [
        "Configure optimizer with learning rate = 5e-5, epochs = 4, eps = 1e-8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gufw1nhCIJDj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c4e5009-90aa-4cbc-f2ea-e06fd9c37c88"
      },
      "source": [
        "\n",
        "from transformers import AdamW, BertConfig, get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "# # Load the AdamW optimizer\n",
        "# optimizer = AdamW(model.parameters(),\n",
        "#                   lr = 5e-5, # args.learning_rate\n",
        "#                   eps = 1e-8 # args.adam_epsilon\n",
        "#                 )\n",
        "\n",
        "# This code is taken from:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L102\n",
        "\n",
        "# Don't apply weight decay to any parameters whose names include these tokens.\n",
        "# (Here, the BERT doesn't have `gamma` or `beta` parameters, only `bias` terms)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "# Separate the `weight` parameters from the `bias` parameters.\n",
        "# - For the `weight` parameters, this specifies a 'weight_decay_rate' of 0.01.\n",
        "# - For the `bias` parameters, the 'weight_decay_rate' is 0.0.\n",
        "optimizer_grouped_parameters = [\n",
        "    # Filter for all parameters which *don't* include 'bias', 'gamma', 'beta'.\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.3},\n",
        "\n",
        "    # Filter for parameters which *do* include those.\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "# Note - `optimizer_grouped_parameters` only includes the parameter values, not\n",
        "# the names.\n",
        "\n",
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 5e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "\n",
        "# Number of training epochs\n",
        "epochs = 2\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLaiL__2IiW2"
      },
      "source": [
        "time formating function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b8UuFPMIifH"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nInb0rfWIxDt"
      },
      "source": [
        "Training code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "EfELsOJsIxMk",
        "outputId": "f683dbe4-afb5-4f46-82cc-627ec40c04a4"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to\n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because\n",
        "        # accumulating the gradients is \"convenient while training RNNs\".\n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here:\n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids,\n",
        "                    token_type_ids=None,\n",
        "                    attention_mask=b_input_mask,\n",
        "                    labels=b_labels)\n",
        "\n",
        "        # The call to `model` always returns a tuple, so we need to pull the\n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value\n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.4f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "    print(\"\")\n",
        "    print(\"Validation...\")\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    # Put the model into evaluation mode\n",
        "    model.eval()\n",
        "    # Reset the validation loss for this epoch.\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    predictions , true_labels = [], []\n",
        "    for batch in validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Telling the model not to compute or store gradients,\n",
        "        # saving memory and speeding up validation\n",
        "        with torch.no_grad():\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have not provided labels.\n",
        "            outputs = model(b_input_ids, token_type_ids=None,\n",
        "                            attention_mask=b_input_mask, labels=b_labels)\n",
        "        # Move logits and labels to CPU\n",
        "        logits = outputs[1].detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        eval_loss += outputs[0].item()\n",
        "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "        predictionss = np.asarray(predictions)\n",
        "        true_labels.extend(label_ids)\n",
        "\n",
        "    eval_loss = eval_loss / len(validation_dataloader)\n",
        "    print(\"  Average Validation loss: {0:.4f}\".format(eval_loss))\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of    431.    Elapsed: 0:22:05.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-4b3cc66bd632>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m                     \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_input_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     labels=b_labels)\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# The call to `model` always returns a tuple, so we need to pull the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1749\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m         )\n\u001b[1;32m   1753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m         )\n\u001b[1;32m   1008\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m                 )\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         )\n\u001b[1;32m    479\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key_query\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg6p7luALyUb"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "dXu3scKhK8XL",
        "outputId": "f7b72f70-f5f8-479d-c689-87fd807f1f5f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwDptGc_K8Nm"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7xbbOFnLx7b",
        "outputId": "748b763d-6229-44a4-81da-348cd529cbe8"
      },
      "source": [
        "\n",
        "\n",
        "test_sentence = \"\"\" Periodontal disease, also known as gum disease, is a set of inflammatory conditions affecting the tissues surrounding the teeth.[3] In its early stage, called gingivitis, the gums become swollen, red, and may bleed.[3] In its more serious form, called periodontitis, the gums can pull away from the tooth, bone can be lost, and the teeth may loosen or fall out.[3] Bad breath may also occur.[1]\n",
        "\n",
        "Periodontal disease is generally due to bacteria in the mouth infecting the tissue around the teeth.[3] Factors that increase the risk of disease include smoking, diabetes, HIV/AIDS, family history, and certain medications.[1] Diagnosis is by inspecting the gum tissue around the teeth both visually and with a probe and X-rays looking for bone loss around the teeth.[1][5]\n",
        "\n",
        "Treatment involves good oral hygiene and regular professional teeth cleaning.[3] Recommended oral hygiene include daily brushing and flossing.[3] In certain cases antibiotics or dental surgery may be recommended.[6] Globally 538 million people were estimated to be affected in 2015.[4] In the United States nearly half of those over the age of 30 are affected to some degree, and about 70% of those over 65 have the condition.[3] Males are affected more often than females.[3] \"\"\"\n",
        "tokenized_sentence = tokenizer.encode(test_sentence)\n",
        "print(tokenized_sentence)\n",
        "input_ids = torch.tensor([tokenized_sentence]).cuda()\n",
        "with torch.no_grad():\n",
        "    output = model(input_ids)\n",
        "label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n",
        "# join bpe split tokens\n",
        "tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
        "print(tokens)\n",
        "print(label_indices[0])\n",
        "new_tokens, new_labels = [], []\n",
        "for token, label_idx in zip(tokens, label_indices[0]):\n",
        "    if token.startswith(\"##\"):\n",
        "        new_tokens[-1] = new_tokens[-1] + token[2:]\n",
        "    else:\n",
        "        new_labels.append(index_2_label_map.get(label_idx))\n",
        "        new_tokens.append(token)\n",
        "for token, label in zip(new_tokens, new_labels):\n",
        "    print(\"{}\\t{}\".format(label, token))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 16477, 9921, 1348, 3653, 117, 1145, 1227, 1112, 19956, 3653, 117, 1110, 170, 1383, 1104, 22653, 2975, 12759, 1103, 14749, 3376, 1103, 3307, 119, 164, 124, 166, 1130, 1157, 1346, 2016, 117, 1270, 176, 1158, 11083, 10721, 117, 1103, 19956, 1116, 1561, 13930, 117, 1894, 117, 1105, 1336, 24752, 119, 164, 124, 166, 1130, 1157, 1167, 3021, 1532, 117, 1270, 1669, 9921, 10721, 117, 1103, 19956, 1116, 1169, 3373, 1283, 1121, 1103, 14051, 117, 6028, 1169, 1129, 1575, 117, 1105, 1103, 3307, 1336, 5768, 1179, 1137, 2303, 1149, 119, 164, 124, 166, 6304, 2184, 1336, 1145, 4467, 119, 164, 122, 166, 16477, 9921, 1348, 3653, 1110, 2412, 1496, 1106, 10548, 1107, 1103, 1779, 1107, 11916, 1158, 1103, 7918, 1213, 1103, 3307, 119, 164, 124, 166, 15926, 1116, 1115, 2773, 1103, 3187, 1104, 3653, 1511, 9987, 117, 17972, 117, 9622, 120, 9837, 117, 1266, 1607, 117, 1105, 2218, 23897, 119, 164, 122, 166, 12120, 8517, 27078, 1110, 1118, 25151, 1158, 1103, 19956, 7918, 1213, 1103, 3307, 1241, 19924, 1105, 1114, 170, 17357, 1105, 161, 118, 11611, 1702, 1111, 6028, 2445, 1213, 1103, 3307, 119, 164, 122, 166, 164, 126, 166, 19165, 6808, 1363, 9619, 177, 21431, 1105, 2366, 1848, 3307, 9374, 119, 164, 124, 166, 11336, 8178, 2354, 4902, 9619, 177, 21431, 1511, 3828, 13398, 1105, 22593, 13159, 1158, 119, 164, 124, 166, 1130, 2218, 2740, 2848, 25523, 1137, 15360, 6059, 1336, 1129, 6315, 119, 164, 127, 166, 5357, 1193, 4389, 1604, 1550, 1234, 1127, 3555, 1106, 1129, 4634, 1107, 1410, 119, 164, 125, 166, 1130, 1103, 1244, 1311, 2212, 1544, 1104, 1343, 1166, 1103, 1425, 1104, 1476, 1132, 4634, 1106, 1199, 2178, 117, 1105, 1164, 3102, 110, 1104, 1343, 1166, 2625, 1138, 1103, 3879, 119, 164, 124, 166, 7689, 1132, 4634, 1167, 1510, 1190, 3032, 119, 164, 124, 166, 102]\n",
            "['[CLS]', 'Period', '##ont', '##al', 'disease', ',', 'also', 'known', 'as', 'gum', 'disease', ',', 'is', 'a', 'set', 'of', 'inflammatory', 'conditions', 'affecting', 'the', 'tissues', 'surrounding', 'the', 'teeth', '.', '[', '3', ']', 'In', 'its', 'early', 'stage', ',', 'called', 'g', '##ing', '##iv', '##itis', ',', 'the', 'gum', '##s', 'become', 'swollen', ',', 'red', ',', 'and', 'may', 'bleed', '.', '[', '3', ']', 'In', 'its', 'more', 'serious', 'form', ',', 'called', 'period', '##ont', '##itis', ',', 'the', 'gum', '##s', 'can', 'pull', 'away', 'from', 'the', 'tooth', ',', 'bone', 'can', 'be', 'lost', ',', 'and', 'the', 'teeth', 'may', 'loose', '##n', 'or', 'fall', 'out', '.', '[', '3', ']', 'Bad', 'breath', 'may', 'also', 'occur', '.', '[', '1', ']', 'Period', '##ont', '##al', 'disease', 'is', 'generally', 'due', 'to', 'bacteria', 'in', 'the', 'mouth', 'in', '##fect', '##ing', 'the', 'tissue', 'around', 'the', 'teeth', '.', '[', '3', ']', 'Factor', '##s', 'that', 'increase', 'the', 'risk', 'of', 'disease', 'include', 'smoking', ',', 'diabetes', ',', 'HIV', '/', 'AIDS', ',', 'family', 'history', ',', 'and', 'certain', 'medications', '.', '[', '1', ']', 'Di', '##ag', '##nosis', 'is', 'by', 'inspect', '##ing', 'the', 'gum', 'tissue', 'around', 'the', 'teeth', 'both', 'visually', 'and', 'with', 'a', 'probe', 'and', 'X', '-', 'rays', 'looking', 'for', 'bone', 'loss', 'around', 'the', 'teeth', '.', '[', '1', ']', '[', '5', ']', 'Treatment', 'involves', 'good', 'oral', 'h', '##ygiene', 'and', 'regular', 'professional', 'teeth', 'cleaning', '.', '[', '3', ']', 'Re', '##com', '##men', '##ded', 'oral', 'h', '##ygiene', 'include', 'daily', 'brushing', 'and', 'fl', '##oss', '##ing', '.', '[', '3', ']', 'In', 'certain', 'cases', 'anti', '##biotics', 'or', 'dental', 'surgery', 'may', 'be', 'recommended', '.', '[', '6', ']', 'Global', '##ly', '53', '##8', 'million', 'people', 'were', 'estimated', 'to', 'be', 'affected', 'in', '2015', '.', '[', '4', ']', 'In', 'the', 'United', 'States', 'nearly', 'half', 'of', 'those', 'over', 'the', 'age', 'of', '30', 'are', 'affected', 'to', 'some', 'degree', ',', 'and', 'about', '70', '%', 'of', 'those', 'over', '65', 'have', 'the', 'condition', '.', '[', '3', ']', 'Males', 'are', 'affected', 'more', 'often', 'than', 'females', '.', '[', '3', ']', '[SEP]']\n",
            "[2 0 0 0 1 2 2 2 2 0 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0\n",
            " 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 0 0 0 1 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 1 1 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 1 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2]\n",
            "O\t[CLS]\n",
            "B\tPeriodontal\n",
            "I\tdisease\n",
            "O\t,\n",
            "O\talso\n",
            "O\tknown\n",
            "O\tas\n",
            "B\tgum\n",
            "I\tdisease\n",
            "O\t,\n",
            "O\tis\n",
            "O\ta\n",
            "O\tset\n",
            "O\tof\n",
            "O\tinflammatory\n",
            "O\tconditions\n",
            "O\taffecting\n",
            "O\tthe\n",
            "O\ttissues\n",
            "O\tsurrounding\n",
            "O\tthe\n",
            "O\tteeth\n",
            "O\t.\n",
            "O\t[\n",
            "O\t3\n",
            "O\t]\n",
            "O\tIn\n",
            "O\tits\n",
            "O\tearly\n",
            "O\tstage\n",
            "O\t,\n",
            "O\tcalled\n",
            "B\tgingivitis\n",
            "O\t,\n",
            "O\tthe\n",
            "O\tgums\n",
            "O\tbecome\n",
            "O\tswollen\n",
            "O\t,\n",
            "O\tred\n",
            "O\t,\n",
            "O\tand\n",
            "O\tmay\n",
            "O\tbleed\n",
            "O\t.\n",
            "O\t[\n",
            "O\t3\n",
            "O\t]\n",
            "O\tIn\n",
            "O\tits\n",
            "O\tmore\n",
            "O\tserious\n",
            "O\tform\n",
            "O\t,\n",
            "O\tcalled\n",
            "B\tperiodontitis\n",
            "O\t,\n",
            "O\tthe\n",
            "O\tgums\n",
            "O\tcan\n",
            "O\tpull\n",
            "O\taway\n",
            "O\tfrom\n",
            "O\tthe\n",
            "O\ttooth\n",
            "O\t,\n",
            "O\tbone\n",
            "O\tcan\n",
            "O\tbe\n",
            "O\tlost\n",
            "O\t,\n",
            "O\tand\n",
            "O\tthe\n",
            "O\tteeth\n",
            "O\tmay\n",
            "O\tloosen\n",
            "O\tor\n",
            "O\tfall\n",
            "O\tout\n",
            "O\t.\n",
            "O\t[\n",
            "O\t3\n",
            "O\t]\n",
            "B\tBad\n",
            "B\tbreath\n",
            "O\tmay\n",
            "O\talso\n",
            "O\toccur\n",
            "O\t.\n",
            "O\t[\n",
            "O\t1\n",
            "O\t]\n",
            "B\tPeriodontal\n",
            "I\tdisease\n",
            "O\tis\n",
            "O\tgenerally\n",
            "O\tdue\n",
            "O\tto\n",
            "O\tbacteria\n",
            "O\tin\n",
            "O\tthe\n",
            "O\tmouth\n",
            "O\tinfecting\n",
            "O\tthe\n",
            "O\ttissue\n",
            "O\taround\n",
            "O\tthe\n",
            "O\tteeth\n",
            "O\t.\n",
            "O\t[\n",
            "O\t3\n",
            "O\t]\n",
            "O\tFactors\n",
            "O\tthat\n",
            "O\tincrease\n",
            "O\tthe\n",
            "O\trisk\n",
            "O\tof\n",
            "O\tdisease\n",
            "O\tinclude\n",
            "O\tsmoking\n",
            "O\t,\n",
            "B\tdiabetes\n",
            "O\t,\n",
            "B\tHIV\n",
            "I\t/\n",
            "I\tAIDS\n",
            "O\t,\n",
            "O\tfamily\n",
            "O\thistory\n",
            "O\t,\n",
            "O\tand\n",
            "O\tcertain\n",
            "O\tmedications\n",
            "O\t.\n",
            "O\t[\n",
            "O\t1\n",
            "O\t]\n",
            "O\tDiagnosis\n",
            "O\tis\n",
            "O\tby\n",
            "O\tinspecting\n",
            "O\tthe\n",
            "O\tgum\n",
            "O\ttissue\n",
            "O\taround\n",
            "O\tthe\n",
            "O\tteeth\n",
            "O\tboth\n",
            "O\tvisually\n",
            "O\tand\n",
            "O\twith\n",
            "O\ta\n",
            "O\tprobe\n",
            "O\tand\n",
            "O\tX\n",
            "O\t-\n",
            "O\trays\n",
            "O\tlooking\n",
            "O\tfor\n",
            "B\tbone\n",
            "I\tloss\n",
            "O\taround\n",
            "O\tthe\n",
            "O\tteeth\n",
            "O\t.\n",
            "O\t[\n",
            "O\t1\n",
            "O\t]\n",
            "O\t[\n",
            "O\t5\n",
            "O\t]\n",
            "O\tTreatment\n",
            "O\tinvolves\n",
            "O\tgood\n",
            "O\toral\n",
            "O\thygiene\n",
            "O\tand\n",
            "O\tregular\n",
            "O\tprofessional\n",
            "O\tteeth\n",
            "O\tcleaning\n",
            "O\t.\n",
            "O\t[\n",
            "O\t3\n",
            "O\t]\n",
            "O\tRecommended\n",
            "O\toral\n",
            "O\thygiene\n",
            "O\tinclude\n",
            "O\tdaily\n",
            "O\tbrushing\n",
            "O\tand\n",
            "O\tflossing\n",
            "O\t.\n",
            "O\t[\n",
            "O\t3\n",
            "O\t]\n",
            "O\tIn\n",
            "O\tcertain\n",
            "O\tcases\n",
            "O\tantibiotics\n",
            "O\tor\n",
            "O\tdental\n",
            "O\tsurgery\n",
            "O\tmay\n",
            "O\tbe\n",
            "O\trecommended\n",
            "O\t.\n",
            "O\t[\n",
            "O\t6\n",
            "O\t]\n",
            "O\tGlobally\n",
            "O\t538\n",
            "O\tmillion\n",
            "O\tpeople\n",
            "O\twere\n",
            "O\testimated\n",
            "O\tto\n",
            "O\tbe\n",
            "O\taffected\n",
            "O\tin\n",
            "O\t2015\n",
            "O\t.\n",
            "O\t[\n",
            "O\t4\n",
            "O\t]\n",
            "O\tIn\n",
            "O\tthe\n",
            "O\tUnited\n",
            "O\tStates\n",
            "O\tnearly\n",
            "O\thalf\n",
            "O\tof\n",
            "O\tthose\n",
            "O\tover\n",
            "O\tthe\n",
            "O\tage\n",
            "O\tof\n",
            "O\t30\n",
            "O\tare\n",
            "O\taffected\n",
            "O\tto\n",
            "O\tsome\n",
            "O\tdegree\n",
            "O\t,\n",
            "O\tand\n",
            "O\tabout\n",
            "O\t70\n",
            "O\t%\n",
            "O\tof\n",
            "O\tthose\n",
            "O\tover\n",
            "O\t65\n",
            "O\thave\n",
            "O\tthe\n",
            "O\tcondition\n",
            "O\t.\n",
            "O\t[\n",
            "O\t3\n",
            "O\t]\n",
            "O\tMales\n",
            "O\tare\n",
            "O\taffected\n",
            "O\tmore\n",
            "O\toften\n",
            "O\tthan\n",
            "O\tfemales\n",
            "O\t.\n",
            "O\t[\n",
            "O\t3\n",
            "O\t]\n",
            "O\t[SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0yOwT1Vqg7Q"
      },
      "source": [
        "Load one of the Tests for NCBI or BC5CDR\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzIr7_d9qhSa"
      },
      "source": [
        "#sentences, labels, unique_labels = read_data('/content/drive/MyDrive/MedBrain/NCBI/test.tsv')\n",
        "sentences, labels, unique_labels = read_data('/content/drive/MyDrive/MedBrain/BC5CDR/test.tsv')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKFAUY9UEiqB"
      },
      "source": [
        "Tokenize test data set to test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJYsGgr6Ei5d",
        "outputId": "056c23d8-6c08-4dca-8a5f-f4d1452704af"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Reconstruct the sentence--otherwise `tokenizer` will interpret the list\n",
        "    # of string tokens as having already been tokenized by BERT.\n",
        "    sent_str = ' '.join(sent)\n",
        "\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent_str,                  # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_dict['input_ids'][0])\n",
        "\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'][0])\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])\n",
        "print('Masks:', attention_masks[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  ['Torsade', 'de', 'pointes', 'ventricular', 'tachycardia', 'during', 'low', 'dose', 'intermittent', 'dobutamine', 'treatment', 'in', 'a', 'patient', 'with', 'dilated', 'cardiomyopathy', 'and', 'congestive', 'heart', 'failure', '.']\n",
            "Token IDs: tensor([  101, 19928, 23417,  1162,  1260,  1553,  1279, 21828,  4907,  5552,\n",
            "        27629,  8992, 10542,  1465,  1219,  1822, 13753, 27946,  1202, 16442,\n",
            "        19577,  3252,  1107,   170,  5351,  1114,  4267,  6951,  3621,  2660,\n",
            "         4527,  4184, 23610,  1105, 14255,  7562,  3946,  1762,  4290,   119,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n",
            "Masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjmykxoGE-1u"
      },
      "source": [
        "map the labels to the tokens of test data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDBXjXleE_Cz"
      },
      "source": [
        "# New labels for all of the input sentences.\n",
        "new_labels = []\n",
        "\n",
        "# The special label ID we'll give to \"extra\" tokens.\n",
        "null_label_id = -100\n",
        "\n",
        "# For each sentence...\n",
        "for (sen, orig_labels) in zip(input_ids, labels):\n",
        "\n",
        "    # Create a new list to hold the adjusted labels for this sentence.\n",
        "    padded_labels = []\n",
        "\n",
        "    # This will be our index into the original label list.\n",
        "    orig_labels_i = 0\n",
        "\n",
        "    # For each token in the padded sentence...\n",
        "    for token_id in sen:\n",
        "\n",
        "        # Pull the value out of the tensor.\n",
        "        token_id = token_id.numpy().item()\n",
        "\n",
        "        # If `[PAD]`, `[CLS]`, or `[SEP]`...\n",
        "        if (token_id == tokenizer.pad_token_id) or \\\n",
        "            (token_id == tokenizer.cls_token_id) or \\\n",
        "            (token_id == tokenizer.sep_token_id):\n",
        "\n",
        "            # Assign it the null label.\n",
        "            padded_labels.append(null_label_id)\n",
        "\n",
        "        # If the token string starts with \"##\"...\n",
        "        elif tokenizer.convert_ids_to_tokens(token_id)[0:2] == '##':\n",
        "\n",
        "            # It's a subword token, and not part of the original dataset, so\n",
        "            # assign it the null label.\n",
        "            padded_labels.append(label_2_index_map[orig_labels[orig_labels_i-1]])\n",
        "\n",
        "        # If it's not any of the above...\n",
        "        else:\n",
        "\n",
        "            # This token corresponds to one of the original ones, so assign it\n",
        "            # it's original label.\n",
        "\n",
        "            # Look up the label for this token.\n",
        "            label_str = orig_labels[orig_labels_i]\n",
        "\n",
        "            # Map the label to its ID, and assign it.\n",
        "            padded_labels.append(label_2_index_map[label_str])\n",
        "\n",
        "            # Increment our index into the original labels list.\n",
        "            orig_labels_i += 1\n",
        "\n",
        "    # If we did this right, then the new `padded_labels` list should match\n",
        "    # the length of the tokenized sentence.\n",
        "    assert(len(sen) == len(padded_labels))\n",
        "\n",
        "    # Store the updated labels list for this sentence.\n",
        "    new_labels.append(padded_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC0vTYP8FT8b"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh9IbE3_FUFZ",
        "outputId": "180108d6-14a8-43a4-8a6c-e02e1d5211d0"
      },
      "source": [
        "print('\\nSentence:    ', sentences[2])\n",
        "print('\\nLabels:      ', labels[2])\n",
        "print('\\nBERT Tokens: ', tokenizer.tokenize(' '.join(sentences[2])))\n",
        "print('\\nToken IDs:   ', input_ids[2])\n",
        "print('\\nMask:        ', attention_masks[2])\n",
        "print('\\nNew Labels:  ', new_labels[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence:     ['This', 'report', 'of', 'torsade', 'de', 'pointes', 'ventricular', 'tachycardia', 'during', 'intermittent', 'dobutamine', 'supports', 'the', 'hypothesis', 'that', 'unpredictable', 'fatal', 'arrhythmias', 'may', 'occur', 'even', 'with', 'low', 'doses', 'and', 'in', 'patients', 'with', 'no', 'history', 'of', 'significant', 'rhythm', 'disturbances', '.']\n",
            "\n",
            "Labels:       ['O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "BERT Tokens:  ['This', 'report', 'of', 'to', '##rsa', '##de', 'de', 'point', '##es', 'vent', '##ric', '##ular', 'ta', '##chy', '##card', '##ia', 'during', 'intermittent', 'do', '##but', '##amine', 'supports', 'the', 'hypothesis', 'that', 'unpredictable', 'fatal', 'a', '##rr', '##hy', '##th', '##mia', '##s', 'may', 'occur', 'even', 'with', 'low', 'doses', 'and', 'in', 'patients', 'with', 'no', 'history', 'of', 'significant', 'rhythm', 'disturbance', '##s', '.']\n",
            "\n",
            "Token IDs:    tensor([  101,  1188,  2592,  1104,  1106, 24129,  2007,  1260,  1553,  1279,\n",
            "        21828,  4907,  5552, 27629,  8992, 10542,  1465,  1219, 27946,  1202,\n",
            "        16442, 19577,  6253,  1103, 11066,  1115, 24213, 11874,   170, 11096,\n",
            "         7889,  1582,  8191,  1116,  1336,  4467,  1256,  1114,  1822, 24429,\n",
            "         1105,  1107,  4420,  1114,  1185,  1607,  1104,  2418,  6795, 19019,\n",
            "         1116,   119,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n",
            "\n",
            "Mask:         tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "\n",
            "New Labels:   [-100, 2, 2, 2, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYZkQ9CaFfl4"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN8YlUhHFfu6"
      },
      "source": [
        "# Convert the lists into PyTorch tensors.\n",
        "\n",
        "# `input_ids` is a list of tensor arrays--stack them into a matrix.\n",
        "pt_input_ids = torch.stack(input_ids, dim=0)\n",
        "\n",
        "# `attention_masks` is a list of tensor arrays--stack them into a matrix.\n",
        "pt_attention_masks = torch.stack(attention_masks, dim=0)\n",
        "\n",
        "# Labels is a list of lists. Convert it into a tensor matrix.\n",
        "pt_labels = torch.tensor(new_labels, dtype=torch.long)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1HBidUUFhMX"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut8DimB0Fhlb"
      },
      "source": [
        "# Set the batch size.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(pt_input_ids, pt_attention_masks, pt_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLcyL3hCFquS"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zrccZ0JFq2_",
        "outputId": "063278f3-da66-46e2-f0cf-4fd5cedfdd0b"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(pt_input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict\n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  # Telling the model not to compute or store gradients, saving memory and\n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None,\n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 4,797 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEaXpEvXFz6p"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4QLKLF9F0Iu",
        "outputId": "5d91935c-5dc6-4f41-d9f0-4f37044b0457"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "new = np.array(predictions)\n",
        "\n",
        "print(new.shape)\n",
        "\n",
        "# First, combine the results across the batches.\n",
        "all_predictions = np.concatenate(predictions, axis=0)\n",
        "all_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "print(\"After flattening the batches, the predictions have shape:\")\n",
        "print(\"    \", all_predictions.shape)\n",
        "\n",
        "# Next, let's remove the third dimension (axis 2), which has the scores\n",
        "# for all 18 labels.\n",
        "\n",
        "# For each token, pick the label with the highest score.\n",
        "predicted_label_ids = np.argmax(all_predictions, axis=2)\n",
        "\n",
        "print(\"\\nAfter choosing the highest scoring label for each token:\")\n",
        "print(\"    \", predicted_label_ids.shape)\n",
        "\n",
        "# Finally, for the sake of scoring, we don't actually care about the different\n",
        "# sentences--we just look at whether the model made correct predictions for the\n",
        "# individual tokens.\n",
        "\n",
        "# Eliminate axis 0, which corresponds to the sentences.\n",
        "predicted_label_ids = np.concatenate(predicted_label_ids, axis=0)\n",
        "all_true_labels = np.concatenate(all_true_labels, axis=0)\n",
        "\n",
        "print(\"\\nAfter flattening the sentences, we have predictions:\")\n",
        "print(\"    \", predicted_label_ids.shape)\n",
        "print(\"and ground truth:\")\n",
        "print(\"    \", all_true_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300,)\n",
            "After flattening the batches, the predictions have shape:\n",
            "     (4797, 128, 4)\n",
            "\n",
            "After choosing the highest scoring label for each token:\n",
            "     (4797, 128)\n",
            "\n",
            "After flattening the sentences, we have predictions:\n",
            "     (614016,)\n",
            "and ground truth:\n",
            "     (614016,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgJXwBwuGpFf"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X7Xx6BxGpR3",
        "outputId": "4c4b20c6-fbde-4020-98d2-2e18f661b863"
      },
      "source": [
        "# Construct new lists of predictions which don't include any null tokens.\n",
        "real_token_predictions = []\n",
        "real_token_labels = []\n",
        "\n",
        "# For each of the input tokens in the dataset...\n",
        "for i in range(len(all_true_labels)):\n",
        "\n",
        "    # If it's not a token with a null label...\n",
        "    if not all_true_labels[i] == -100:\n",
        "\n",
        "        # Add the prediction and the ground truth to their lists.\n",
        "        real_token_predictions.append(predicted_label_ids[i])\n",
        "        real_token_labels.append(all_true_labels[i])\n",
        "\n",
        "print(\"Before filtering out `null` tokens, length = {:,}\".format(len(all_true_labels)))\n",
        "print(\" After filtering out `null` tokens, length = {:,}\".format(len(real_token_labels)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before filtering out `null` tokens, length = 614,016\n",
            " After filtering out `null` tokens, length = 172,750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIigQ-Z0H2kD"
      },
      "source": [
        "f1 score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njsBKW9EH2yJ",
        "outputId": "3023cbca-d2c2-457b-99af-ca050b8cfa51"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Calculate the F1 score. Because this is a multi-class problem, we have\n",
        "# to set the `average` parameter.\n",
        "f1 = f1_score(real_token_labels, real_token_predictions, average='micro')\n",
        "\n",
        "print (\"F1 score: {:.2%}\".format(f1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score: 97.31%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwSdo6FRp0un"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZYN7DVXp05r",
        "outputId": "9b6c1420-dddd-4efb-d4f7-55943b2dacbe"
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/MedBrain/model_save_Final-2/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to /content/drive/MyDrive/MedBrain/model_save_Final-2/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/MedBrain/model_save_Final-2/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/MedBrain/model_save_Final-2/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/MedBrain/model_save_Final-2/vocab.txt',\n",
              " '/content/drive/MyDrive/MedBrain/model_save_Final-2/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z97I0FyITQtN"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyJXzjgOF2EQ",
        "outputId": "dfab5565-aec0-41fa-a682-347f343c1937"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyNpAxHbTvGN",
        "outputId": "911cf5d2-1c5e-45f5-87c5-7501e2e0bd8e"
      },
      "source": [
        "!pip install transformers\n",
        "!tar -C /content/drive/MyDrive/MedBrain/ -cvzf model_save_Final-2.tar.gz model_save_Final-2\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "model_save_Final-2/\n",
            "model_save_Final-2/config.json\n",
            "model_save_Final-2/pytorch_model.bin\n",
            "model_save_Final-2/tokenizer_config.json\n",
            "model_save_Final-2/special_tokens_map.json\n",
            "model_save_Final-2/vocab.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuoZ8ED8Ibsv"
      },
      "source": [
        "import tarfile\n",
        "\n",
        "def read_model(model_path: str=None, s3_bucket: str=None, file_prefix: str=None):\n",
        "      if s3_bucket and file_prefix:\n",
        "            obj = s3.get_object(Bucket=s3_bucket, Key=file_prefix)\n",
        "            bytestream = io.BytesIO(obj['Body'].read())\n",
        "            tar = tarfile.open(fileobj=bytestream, mode=\"r:gz\")\n",
        "            for member in tar.getmembers():\n",
        "              if member.name.endswith(\".bin\"):\n",
        "                  return tar.extractfile(member)\n",
        "      if model_path:\n",
        "          tar = tarfile.open(model_path, mode=\"r:gz\")\n",
        "          for member in tar.getmembers():\n",
        "              if member.name.endswith(\".bin\"):\n",
        "                  return tar.extractfile(member)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7MwtlhIIeW3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "cccba887-e8e5-458c-e393-0661a6249a78"
      },
      "source": [
        "import io\n",
        "import torch\n",
        "from transformers import AutoConfig, AutoModelForTokenClassification, AutoTokenizer\n",
        "\n",
        "file_object = read_model(model_path=\"/content/model_save_Final.tar.gz\")\n",
        "# read = file_object.read(20)\n",
        "# print (io.BytesIO(read))\n",
        "\n",
        "config = AutoConfig.from_pretrained(f'/content/drive/MyDrive/MedBrain/model_save_Final/config.json')\n",
        "device = torch.device(\"cpu\")\n",
        "state = torch.load(io.BytesIO(file_object.read()),map_location=torch.device('cpu'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-a4b6cbe87151>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForTokenClassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfile_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/model_save_Final.tar.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# read = file_object.read(20)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# print (io.BytesIO(read))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'read_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkrSBce9Nje5"
      },
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "                        pretrained_model_name_or_path=None, state_dict=state, config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub9lPPp3N3jr"
      },
      "source": [
        "from transformers import AutoConfig, AutoModelForTokenClassification, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/MedBrain/model_save_Final/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf1n6fRMOu0U",
        "outputId": "e2019271-6761-40e4-8471-c6bd8389e537"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Map each unique label to an integer.\n",
        "label_2_index_map = {'B': 0, 'I': 1, 'O': 2, 'X': -100}\n",
        "index_2_label_map = {0: 'B', 1: 'I', 2: 'O', -100: 'X'}\n",
        "\n",
        "test_sentence = \"\"\" A tumor was found in the left ovary \"\"\"\n",
        "tokenized_sentence = tokenizer.encode(test_sentence)\n",
        "input_ids = torch.tensor([tokenized_sentence])\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model(input_ids)\n",
        "label_indices = np.argmax(output[0].numpy(), axis=2)\n",
        "# join bpe split tokens\n",
        "tokens = tokenizer.convert_ids_to_tokens(input_ids.numpy()[0])\n",
        "new_tokens, new_labels = [], []\n",
        "for token, label_idx in zip(tokens, label_indices[0]):\n",
        "    if token.startswith(\"##\"):\n",
        "        new_tokens[-1] = new_tokens[-1] + token[2:]\n",
        "    else:\n",
        "        new_labels.append(index_2_label_map.get(label_idx))\n",
        "        new_tokens.append(token)\n",
        "ret = [{token: label} for token, label in zip(new_tokens, new_labels)]\n",
        "print (ret)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'[CLS]': 'B'}, {'A': 'B'}, {'tumor': 'I'}, {'was': 'B'}, {'found': 'B'}, {'in': 'B'}, {'the': 'B'}, {'left': 'B'}, {'ovary': 'B'}, {'[SEP]': 'B'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Fa-SSOkTQWf"
      },
      "source": [
        "from transformers import BertTokenizer, BertForTokenClassification\n",
        "import os\n",
        "model_dir = '/content/drive/MyDrive/MedBrain/model_save_Final/'\n",
        "\n",
        "tokenizer = BertTokenizer(vocab_file=os.path.join(model_dir, \"vocab.txt\"), do_lower_case=False)\n",
        "model = BertForTokenClassification.from_pretrained(\n",
        "    model_dir,\n",
        "    # we have 4 labels B, I, O and [PAD]\n",
        "    num_labels=4,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GoMAt-qVUxj"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBI3r_V5Va75",
        "outputId": "7abc0d2e-7d5a-4709-8edc-74020bd3f136"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Map each unique label to an integer.\n",
        "label_2_index_map = {'I': 0, 'B': 1, 'O': 2, 'X': -100}\n",
        "index_2_label_map = {0: 'I', 1: 'B', 2: 'O', -100: 'X'}\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('%d GPU(s) are available. The type of the GPU(s) is: %s'% (torch.cuda.device_count(), torch.cuda.get_device_name(0)))\n",
        "\n",
        "else:\n",
        "    print('No GPU is available, using CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "test_sentence = \"\"\" Periodontal disease, also known as gum disease, is a set of inflammatory conditions affecting the tissues surrounding the teeth.[3] In its early stage, called gingivitis, the gums become swollen, red, and may bleed.[3] In its more serious form, called periodontitis, the gums can pull away from the tooth, bone can be lost, and the teeth may loosen or fall out.[3] Bad breath may also occur.[1]\n",
        "\n",
        "Periodontal disease is generally due to bacteria in the mouth infecting the tissue around the teeth.[3] Factors that increase the risk of disease include smoking, diabetes, HIV/AIDS, family history, and certain medications.[1] Diagnosis is by inspecting the gum tissue around the teeth both visually and with a probe and X-rays looking for bone loss around the teeth.[1][5]\n",
        "\n",
        "Treatment involves good oral hygiene and regular professional teeth cleaning.[3] Recommended oral hygiene include daily brushing and flossing.[3] In certain cases antibiotics or dental surgery may be recommended.[6] Globally 538 million people were estimated to be affected in 2015.[4] In the United States nearly half of those over the age of 30 are affected to some degree, and about 70% of those over 65 have the condition.[3] Males are affected more often than females.[3] \"\"\"\n",
        "tokenized_sentence = tokenizer.encode(test_sentence)\n",
        "input_ids = torch.tensor([tokenized_sentence]).to(device)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model(input_ids)\n",
        "label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n",
        "# join bpe split tokens\n",
        "tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
        "new_tokens, new_labels = [], []\n",
        "for token, label_idx in zip(tokens, label_indices[0]):\n",
        "    if token.startswith(\"##\"):\n",
        "        new_tokens[-1] = new_tokens[-1] + token[2:]\n",
        "    else:\n",
        "        new_labels.append(index_2_label_map.get(label_idx))\n",
        "        new_tokens.append(token)\n",
        "for token, label in zip(new_tokens, new_labels):\n",
        "    print(\"{}\\t{}\".format(label, token))\n",
        "\n",
        "# {'O': 0, 'I': 1, 'B': 2, 'X': -100}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 GPU(s) are available. The type of the GPU(s) is: Tesla T4\n",
            "O\t[CLS]\n",
            "B\tPeriodontal\n",
            "I\tdisease\n",
            "O\t,\n",
            "O\talso\n",
            "O\tknown\n",
            "O\tas\n",
            "B\tgum\n",
            "I\tdisease\n",
            "O\t,\n",
            "O\tis\n",
            "O\ta\n",
            "O\tset\n",
            "O\tof\n",
            "O\tinflammatory\n",
            "O\tconditions\n",
            "O\taffecting\n",
            "O\tthe\n",
            "O\ttissues\n",
            "O\tsurrounding\n",
            "O\tthe\n",
            "O\tteeth\n",
            "O\t.\n",
            "O\t[\n",
            "O\t3\n",
            "O\t]\n",
            "O\tIn\n",
            "O\tits\n",
            "O\tearly\n",
            "O\tstage\n",
            "O\t,\n",
            "O\tcalled\n",
            "B\tgingivitis\n",
            "O\t,\n",
            "O\tthe\n",
            "O\tgums\n",
            "O\tbecome\n",
            "O\tswollen\n",
            "O\t,\n",
            "O\tred\n",
            "O\t,\n",
            "O\tand\n",
            "O\tmay\n",
            "O\tbleed\n",
            "O\t.\n",
            "O\t[\n",
            "O\t3\n",
            "O\t]\n",
            "O\tIn\n",
            "O\tits\n",
            "O\tmore\n",
            "O\tserious\n",
            "O\tform\n",
            "O\t,\n",
            "O\tcalled\n",
            "B\tperiodontitis\n",
            "O\t,\n",
            "O\tthe\n",
            "O\tgums\n",
            "O\tcan\n",
            "O\tpull\n",
            "O\taway\n",
            "O\tfrom\n",
            "O\tthe\n",
            "O\ttooth\n",
            "O\t,\n",
            "O\tbone\n",
            "O\tcan\n",
            "O\tbe\n",
            "O\tlost\n",
            "O\t,\n",
            "O\tand\n",
            "O\tthe\n",
            "O\tteeth\n",
            "O\tmay\n",
            "O\tloosen\n",
            "O\tor\n",
            "O\tfall\n",
            "O\tout\n",
            "O\t.\n",
            "O\t[\n",
            "O\t3\n",
            "O\t]\n",
            "O\tBad\n",
            "O\tbreath\n",
            "O\tmay\n",
            "O\talso\n",
            "O\toccur\n",
            "O\t.\n",
            "O\t[\n",
            "O\t1\n",
            "O\t]\n",
            "B\tPeriodontal\n",
            "I\tdisease\n",
            "O\tis\n",
            "O\tgenerally\n",
            "O\tdue\n",
            "O\tto\n",
            "O\tbacteria\n",
            "O\tin\n",
            "O\tthe\n",
            "O\tmouth\n",
            "O\tinfecting\n",
            "O\tthe\n",
            "O\ttissue\n",
            "O\taround\n",
            "O\tthe\n",
            "O\tteeth\n",
            "O\t.\n",
            "O\t[\n",
            "O\t3\n",
            "O\t]\n",
            "O\tFactors\n",
            "O\tthat\n",
            "O\tincrease\n",
            "O\tthe\n",
            "O\trisk\n",
            "O\tof\n",
            "O\tdisease\n",
            "O\tinclude\n",
            "O\tsmoking\n",
            "O\t,\n",
            "B\tdiabetes\n",
            "O\t,\n",
            "B\tHIV\n",
            "I\t/\n",
            "I\tAIDS\n",
            "O\t,\n",
            "O\tfamily\n",
            "O\thistory\n",
            "O\t,\n",
            "O\tand\n",
            "O\tcertain\n",
            "O\tmedications\n",
            "O\t.\n",
            "O\t[\n",
            "O\t1\n",
            "O\t]\n",
            "O\tDiagnosis\n",
            "O\tis\n",
            "O\tby\n",
            "O\tinspecting\n",
            "O\tthe\n",
            "O\tgum\n",
            "O\ttissue\n",
            "O\taround\n",
            "O\tthe\n",
            "O\tteeth\n",
            "O\tboth\n",
            "O\tvisually\n",
            "O\tand\n",
            "O\twith\n",
            "O\ta\n",
            "O\tprobe\n",
            "O\tand\n",
            "O\tX\n",
            "O\t-\n",
            "O\trays\n",
            "O\tlooking\n",
            "O\tfor\n",
            "B\tbone\n",
            "I\tloss\n",
            "O\taround\n",
            "O\tthe\n",
            "O\tteeth\n",
            "O\t.\n",
            "O\t[\n",
            "O\t1\n",
            "O\t]\n",
            "O\t[\n",
            "O\t5\n",
            "O\t]\n",
            "O\tTreatment\n",
            "O\tinvolves\n",
            "O\tgood\n",
            "O\toral\n",
            "O\thygiene\n",
            "O\tand\n",
            "O\tregular\n",
            "O\tprofessional\n",
            "O\tteeth\n",
            "O\tcleaning\n",
            "O\t.\n",
            "O\t[\n",
            "O\t3\n",
            "O\t]\n",
            "O\tRecommended\n",
            "O\toral\n",
            "O\thygiene\n",
            "O\tinclude\n",
            "O\tdaily\n",
            "O\tbrushing\n",
            "O\tand\n",
            "O\tflossing\n",
            "O\t.\n",
            "O\t[\n",
            "O\t3\n",
            "O\t]\n",
            "O\tIn\n",
            "O\tcertain\n",
            "O\tcases\n",
            "O\tantibiotics\n",
            "O\tor\n",
            "O\tdental\n",
            "O\tsurgery\n",
            "O\tmay\n",
            "O\tbe\n",
            "O\trecommended\n",
            "O\t.\n",
            "O\t[\n",
            "O\t6\n",
            "O\t]\n",
            "O\tGlobally\n",
            "O\t538\n",
            "O\tmillion\n",
            "O\tpeople\n",
            "O\twere\n",
            "O\testimated\n",
            "O\tto\n",
            "O\tbe\n",
            "O\taffected\n",
            "O\tin\n",
            "O\t2015\n",
            "O\t.\n",
            "O\t[\n",
            "O\t4\n",
            "O\t]\n",
            "O\tIn\n",
            "O\tthe\n",
            "O\tUnited\n",
            "O\tStates\n",
            "O\tnearly\n",
            "O\thalf\n",
            "O\tof\n",
            "O\tthose\n",
            "O\tover\n",
            "O\tthe\n",
            "O\tage\n",
            "O\tof\n",
            "O\t30\n",
            "O\tare\n",
            "O\taffected\n",
            "O\tto\n",
            "O\tsome\n",
            "O\tdegree\n",
            "O\t,\n",
            "O\tand\n",
            "O\tabout\n",
            "O\t70\n",
            "O\t%\n",
            "O\tof\n",
            "O\tthose\n",
            "O\tover\n",
            "O\t65\n",
            "O\thave\n",
            "O\tthe\n",
            "O\tcondition\n",
            "O\t.\n",
            "O\t[\n",
            "O\t3\n",
            "O\t]\n",
            "O\tMales\n",
            "O\tare\n",
            "O\taffected\n",
            "O\tmore\n",
            "O\toften\n",
            "O\tthan\n",
            "O\tfemales\n",
            "O\t.\n",
            "O\t[\n",
            "O\t3\n",
            "O\t]\n",
            "O\t[SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gw_PGWmC0Yu6"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9oJZQbP0Y6P",
        "outputId": "770b86bc-9bda-4179-a47f-ccf40fe824bf"
      },
      "source": [
        "!zip -r /content/my_bert.zip /content/drive/MyDrive/MedBrain/model_save_Final"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/drive/MyDrive/MedBrain/model_save_Final/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/MedBrain/model_save_Final/config.json (deflated 51%)\n",
            "  adding: content/drive/MyDrive/MedBrain/model_save_Final/pytorch_model.bin (deflated 7%)\n",
            "  adding: content/drive/MyDrive/MedBrain/model_save_Final/tokenizer_config.json (deflated 39%)\n",
            "  adding: content/drive/MyDrive/MedBrain/model_save_Final/special_tokens_map.json (deflated 40%)\n",
            "  adding: content/drive/MyDrive/MedBrain/model_save_Final/vocab.txt (deflated 49%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLWKzXlh7YTG",
        "outputId": "b16ea2af-17f6-47b3-cdc5-af11b0647585"
      },
      "source": [
        "!pip install numpy\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.19.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"manueltonneau/clinicalcovid-bert-base-cased\")\n",
        "model = AutoModel.from_pretrained(\"manueltonneau/clinicalcovid-bert-base-cased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "40eb263bc20d40e9a142cdecd5c05360",
            "c7d90a8c8a5846bfa29a5e1bd71d0154",
            "545c3581135c4b64bc1971e8f1db4bb8",
            "a8b8f52e86754bcebcf6f0a57a8be279",
            "b0966d09aa924854b3983250e7680003",
            "b0e88b19ee78418888e053670b2bd9a2",
            "22899254c8ba4ac8b657a2f2afbf8a71",
            "ee783cb5e7ac4c0d99d38555fe8a6d19",
            "4192bc915e0e434e904b7e17685800fb",
            "745ce6f32e6e40a093f6049064a919a1",
            "c1022334bb9f4c4183ad0e2a059ef65b",
            "f623d40aa83e4197900a0ae46c62543e",
            "7554a3ad5e284f0ca6a40374dca1dc0d",
            "5fba35b3327e4a32a9bca2a91fda0b3c",
            "071dc1f383bd4e46b2d762682d77aa5c",
            "218cfc0b9d1341ddb7adadad3769c3b1",
            "1a2986ff629e44529c219f74bfc3692f",
            "30a35b8dbdb44a81bd002e99d6fcb658",
            "3924565793704a5091d0c729acef6da8",
            "11cff03a77a24c3cb6a7d24e0a4789f8",
            "2a6924d6388141cf9f5e76e21fea1a35",
            "7002c9ccf8024cab98b6364bcde73b46",
            "fe289f09ea1946ba8e5290ce679b70bc",
            "e3c2fe052b12481fae56a5888cc9fbc3",
            "be2cf9fedac84b748a40b17ca91cb285",
            "37a45dfef49e4894a856191d2c268ad1",
            "ed54ef39f7124924af2f893e374fac6d",
            "85e1f2c5044440e49bc05f126debd0ae",
            "4a4847d14eeb4003ae1d2ded4bbe248a",
            "03f315ed6b4d4fb5bebe088602218299",
            "a7408f2a8fff48dba28b195c879502ea",
            "b3e1d46ff2a442009ef240097ecd6a00",
            "b9c2757672ef4a8484df9aa15fe7fb95"
          ]
        },
        "id": "ZjY7Ovj3TmAh",
        "outputId": "c9c602e8-edfd-4193-f6ac-bcbc31e14c7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/313 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40eb263bc20d40e9a142cdecd5c05360"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f623d40aa83e4197900a0ae46c62543e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe289f09ea1946ba8e5290ce679b70bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at manueltonneau/clinicalcovid-bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    }
  ]
}